[["index.html", "Coding Bookdown for EMRR Preface", " Coding Bookdown for EMRR Catarina Pien 2022-04-27 Preface This book provides example code for stats and working with data in R. We start with basic R skills, plotting and manipulating data. We also have more complex code for making maps, functions, loops, then statistical tests. "],["basics-of-r.html", "Chapter 1 Basics of R", " Chapter 1 Basics of R Creating projects, file structure Reading in data from csv, excel Reading data from online Writing data Column formats (character, numeric, datetime, factor) Datetimes "],["data-manipulation.html", "Chapter 2 Data Manipulation", " Chapter 2 Data Manipulation Pivot wider and longer Complete cases Dplyr select, mutate, rename "],["making-plots.html", "Chapter 3 Making Plots", " Chapter 3 Making Plots 3.0.1 Coding goals We will learn the basics of R as we generate a series of plots. These plots will be based on a real data set produced in our office for the Delta Smelt Resiliency Strategy Aquatic Weed Control Action 3.0.2 Study overview The purpose of this two-year study was to use herbicides to remove invasive aquatic vegetation from potential habitat for endangered delta smelt. In this experiment there were two treated sites and two untreated reference sites. We monitored many aspects of the ecosystem to document changes in response to the herbicide applications. We have data for vegetation biomass and species composition as well as water quality, phytoplankton, zooplankton, and fishes. For now, we will just focus on the vegetation biomass data. 3.0.3 Metadata for data set Description of columns in vegetation biomass data set. date: Date a sample was collected rounded to the nearest month, so the data are plotted by survey month instead of exact date. site: Study sites in the North Delta. Little Hasting (LH) was treated with herbicides to remove aquatic weeds. French Island (FI) is a site near LH that is similar in many ways but remained untreated. rake_no: Samples of aquatic vegetation were collected using a long-handled thatch rake. There were 20-40 samples collected for each site x date combination. mass_kg: Total wet biomass of aquatic vegetation collected from a rake sample. 3.0.4 Helpful resources R for Data Science: This is the primary source for learning how to use the tidyverse packages. Also this whole book was created using RMarkdown! Ill just refer to it as RDS in the lessons below. 3.0.5 Initial set up 3.0.5.1 Install and load required packages For the exercises, youll need the tidyverse which is a suite of packages that are useful for data science, and the lubridate package, which is handy for formatting dates. Packages only need to be installed once, which is why the code to do that is now commented out with the # Make sure the names of the packages are in quotes, or the code wont work. You will need to load the packages you want to use during every session using the library() function. As you load the packages, youll get some warnings and other notifications. Its good to take a look at them, but most of the time, you dont need to worry about them. I turned off printing of messages and warning in my markdown, so you wont see them below. #install.packages(&quot;lubridate&quot;) #install.packages(&quot;tidyverse&quot;) library(lubridate) library(tidyverse) Note: Packages can also be installed from the Packages tab in the lower right pane. 3.0.5.2 Read the data set into R It is often easiest to import data into R as a comma delimited file, which involves using the read.csv() function. You can import data from other types of files too, but the import function will be a little different. The data set we will use is published on the Environmental Data Initiative website, so we can read it using the link to the csv file. veg_data&lt;-read.csv(&quot;https://portal.edirepository.org/nis/dataviewer?packageid=edi.1079.1&amp;entityid=f29d1162866d4e9fb2fdd7355efd4c1e&quot;) 3.0.5.3 Examine the structure of the data set The str() function will show you some useful information about each column including what type of column it is. str(veg_data) ## &#39;data.frame&#39;: 876 obs. of 16 variables: ## $ Site : chr &quot;DI&quot; &quot;DI&quot; &quot;DI&quot; &quot;DI&quot; ... ## $ Site_Type : chr &quot;Treated&quot; &quot;Treated&quot; &quot;Treated&quot; &quot;Treated&quot; ... ## $ Date : chr &quot;2017-05-25&quot; &quot;2017-06-07&quot; &quot;2017-06-07&quot; &quot;2017-05-25&quot; ... ## $ Survey_Month : chr &quot;2017_06&quot; &quot;2017_06&quot; &quot;2017_06&quot; &quot;2017_06&quot; ... ## $ Latitude : num 38.1 38.1 38.1 38.1 38.1 ... ## $ Longitude : num -122 -122 -122 -122 -122 ... ## $ Total_Wet_Biomass_kg : num 0 0 0 0.0055 0.17 0.284 0.304 0.446 0.51 0.518 ... ## $ Egeria_densa : int 0 0 0 50 90 100 100 100 100 100 ... ## $ Elodea_canadensis : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Ceratophyllum_demersum: int 0 0 0 50 0 0 0 0 0 0 ... ## $ Potamogeton_crispus : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Myriophyllum_spicatum : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Stuckenia_pectinata : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Najas_guadalupensis : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Potamogeton_nodosus : int 0 0 0 0 0 0 0 0 0 0 ... ## $ Cabomba_caroliniana : int 0 0 0 0 0 0 0 0 0 0 ... The head() function will show you the first six rows of data. Similarly, the tail() function will show you the last six rows. head(veg_data) ## Site Site_Type Date Survey_Month Latitude Longitude ## 1 DI Treated 2017-05-25 2017_06 38.08299 -121.7239 ## 2 DI Treated 2017-06-07 2017_06 38.08329 -121.7188 ## 3 DI Treated 2017-06-07 2017_06 38.08331 -121.7192 ## 4 DI Treated 2017-05-25 2017_06 38.08399 -121.7198 ## 5 DI Treated 2017-05-25 2017_06 38.08388 -121.7162 ## 6 DI Treated 2017-05-25 2017_06 38.08351 -121.7166 ## Total_Wet_Biomass_kg Egeria_densa Elodea_canadensis Ceratophyllum_demersum ## 1 0.0000 0 0 0 ## 2 0.0000 0 0 0 ## 3 0.0000 0 0 0 ## 4 0.0055 50 0 50 ## 5 0.1700 90 0 0 ## 6 0.2840 100 0 0 ## Potamogeton_crispus Myriophyllum_spicatum Stuckenia_pectinata ## 1 0 0 0 ## 2 0 0 0 ## 3 0 0 0 ## 4 0 0 0 ## 5 0 0 0 ## 6 0 0 0 ## Najas_guadalupensis Potamogeton_nodosus Cabomba_caroliniana ## 1 0 0 0 ## 2 0 0 0 ## 3 0 0 0 ## 4 0 0 0 ## 5 0 0 0 ## 6 0 0 0 tail(veg_data) ## Site Site_Type Date Survey_Month Latitude Longitude ## 871 LH Treated 2018-12-11 2018_12 38.25070 -121.6918 ## 872 LH Treated 2018-12-11 2018_12 38.25174 -121.6937 ## 873 LH Treated 2018-12-11 2018_12 38.24510 -121.6914 ## 874 LH Treated 2018-12-11 2018_12 38.25291 -121.6921 ## 875 LH Treated 2018-12-11 2018_12 38.24797 -121.6935 ## 876 LH Treated 2018-12-11 2018_12 38.25250 -121.6936 ## Total_Wet_Biomass_kg Egeria_densa Elodea_canadensis Ceratophyllum_demersum ## 871 0.610 0 90 0 ## 872 0.746 50 50 0 ## 873 0.834 100 0 0 ## 874 1.026 20 0 80 ## 875 1.082 90 0 0 ## 876 2.562 100 0 0 ## Potamogeton_crispus Myriophyllum_spicatum Stuckenia_pectinata ## 871 10 0 0 ## 872 0 0 0 ## 873 0 0 0 ## 874 0 0 0 ## 875 10 0 0 ## 876 0 0 0 ## Najas_guadalupensis Potamogeton_nodosus Cabomba_caroliniana ## 871 0 0 0 ## 872 0 0 0 ## 873 0 0 0 ## 874 0 0 0 ## 875 0 0 0 ## 876 0 0 0 3.0.5.4 Simplying the data set a bit for our first plotting exercises veg_data_north &lt;- veg_data %&gt;% filter(Site == &quot;LH&quot; | Site == &quot;FI&quot;) 3.0.6 Formatting the data set and making the first plot 3.0.6.1 Format the date column The column type looks fine for all the columns except the date. We need to change it from factor to date. This is where the lubridate package comes in handy. The original format of the date in our tibble is month-day-year, so we use the mdy() function. veg_data_north$Date&lt;-ymd(veg_data_north$Date) glimpse(veg_data_north) ## Rows: 536 ## Columns: 16 ## $ Site &lt;chr&gt; &quot;FI&quot;, &quot;FI&quot;, &quot;FI&quot;, &quot;FI&quot;, &quot;FI&quot;, &quot;FI&quot;, &quot;FI&quot;, &quot;FI&quot;,~ ## $ Site_Type &lt;chr&gt; &quot;Reference&quot;, &quot;Reference&quot;, &quot;Reference&quot;, &quot;Referen~ ## $ Date &lt;date&gt; 2017-06-09, 2017-05-26, 2017-06-09, 2017-06-07~ ## $ Survey_Month &lt;chr&gt; &quot;2017_06&quot;, &quot;2017_06&quot;, &quot;2017_06&quot;, &quot;2017_06&quot;, &quot;20~ ## $ Latitude &lt;dbl&gt; 38.27472, 38.26994, 38.27605, 38.27073, 38.2732~ ## $ Longitude &lt;dbl&gt; -121.7002, -121.6993, -121.6971, -121.7005, -12~ ## $ Total_Wet_Biomass_kg &lt;dbl&gt; 0.0000, 0.0840, 0.0917, 0.1780, 0.2420, 0.3080,~ ## $ Egeria_densa &lt;int&gt; 0, 50, 0, 0, 70, 20, 70, 0, 90, 0, 0, 0, 80, 20~ ## $ Elodea_canadensis &lt;int&gt; 0, 0, 50, 20, 10, 40, 10, 80, 0, 70, 50, 100, 0~ ## $ Ceratophyllum_demersum &lt;int&gt; 0, 0, 0, 0, 0, 0, 20, 0, 0, 30, 0, 0, 20, 0, 30~ ## $ Potamogeton_crispus &lt;int&gt; 0, 0, 0, 40, 10, 30, 0, 20, 0, 0, 0, 0, 0, 0, 0~ ## $ Myriophyllum_spicatum &lt;int&gt; 0, 50, 50, 40, 0, 10, 0, 0, 0, 0, 50, 0, 0, 80,~ ## $ Stuckenia_pectinata &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ ## $ Najas_guadalupensis &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ ## $ Potamogeton_nodosus &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ ## $ Cabomba_caroliniana &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~ Note that the dollar sign is used to specify a column within a data frame or tibble (i.e., dataframe$column) 3.0.6.2 Start exploring the vegetation biomass data by plotting them as a histogram ggplot(data=veg_data, aes(Total_Wet_Biomass_kg)) + geom_histogram() Note: R warns you that six values were removed because they are NA which is not a number. Keep in mind that there are NAs in this data set. It will be important later. 3.0.7 Summarize the data in new tibble Create a new tibble that summarizes the mass data. Calculate sample count, mean, and standard deviation for each date at each site. Dont forget to account for the NA values when doing your summary stats. The final data set should have columns: date, site, count, mean, sd. Try using the pipe (%&gt;%) to do all of this in one block of code. The keyboard shortcut for pipe: press and hold Shift + Control + M. See Help menu at the top for more RStudio keyboard shortcuts. veg_data_north_stats&lt;-veg_data_north %&gt;% #name of the source tibble group_by(Site, Date,Survey_Month) %&gt;% #columns of tibble to group by summarize( count = n(), #counts number of samples for each site x date combo mean = mean(Total_Wet_Biomass_kg, na.rm=T), #calculates means sd = sd(Total_Wet_Biomass_kg, na.rm=T) #calculates standard deviations ) 3.0.8 Plot time series for each study site separately Now, we will make plots with the summary stats we generated. The plot will show the mean vegetation biomass through time. Plot the mean values as points and connect the means with lines to make the pattern easier to see. For general background, see RDS sections 3 (Data Visualization) and 7 (Exploratory Data Analysis). Neither section will show you how to make this specific plot though. Check out the example below for more relevant examples. http://www.sthda.com/english/wiki/ggplot2-line-plot-quick-start-guide-r-software-and-data-visualization For this, use the tibble you made in Exercise #3 with the summary stats for both sites. Also, add the error bars indicating the standard deviations around each mean. Make the points and lines associated with each of the two sites different colors so they can be easily distinguished. For color blind folks, also use different point types (e.g., circles vs. triangles) and different line types (e.g., solid vs dashed). To see all the point and line type options check out this webpage For color options, check out this webpage In this plot, the line types, point types, and colors are different between sites but just using defaults (veg_plot &lt;- ggplot(veg_data_north_stats, aes(x=Date, y=mean, group=Site, color=Site, shape=Site)) + geom_line(aes(linetype=Site))+ geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width = 1, position=position_dodge(2)) + geom_point() ) This is the same plot but with custom line types, point types, and colors (veg_plot_custom &lt;-ggplot(veg_data_north_stats, aes(x=Date, y=mean, group=Site, shape=Site, color=Site, fill=Site)) + geom_line(aes(linetype=Site))+ geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width = 1, position=position_dodge(2)) + geom_point()+ scale_color_manual(values =c(&quot;midnightblue&quot;,&quot;darkorange3&quot;), aesthetics = c(&quot;colour&quot;, &quot;fill&quot;))+ scale_shape_manual(values = c(21, 25))+ scale_linetype_manual(values = c(2,3)) ) We can also plot the time series for sites in separate panels ggplot(veg_data_north_stats, aes(x=Date, y=mean, group=Site, shape=Site, color=Site, fill=Site)) + geom_line(aes(linetype=Site))+ geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width = 1, position=position_dodge(2)) + geom_point()+ scale_color_manual(values =c(&quot;midnightblue&quot;,&quot;darkorange3&quot;), aesthetics = c(&quot;colour&quot;, &quot;fill&quot;))+ scale_shape_manual(values = c(21, 25))+ scale_linetype_manual(values = c(2,3))+ facet_grid(Site~.) If we prefer, barplots we can create those. ggplot(veg_data_north_stats, aes(x=Date, y=mean, group=Site, shape=Site, color=Site, fill=Site)) + geom_bar(stat=&quot;identity&quot;,width=15)+ geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width = 1) + scale_color_manual(values =c(&quot;midnightblue&quot;,&quot;darkorange3&quot;), aesthetics = c(&quot;colour&quot;, &quot;fill&quot;))+ facet_grid(Site~.) Or boxplots ggplot(veg_data_north_stats, aes(x=Date, y=mean, group=Site, shape=Site, color=Site, fill=Site)) + geom_boxplot()+ scale_color_manual(values =c(&quot;midnightblue&quot;,&quot;darkorange3&quot;), aesthetics = c(&quot;colour&quot;, &quot;fill&quot;))+ facet_grid(Site~.) Next, lets look at the correlations in vegetation biomass between sites. You can export these plots as imaging using code. I exported them as PNG files, but there are other options. #French Island plot #ggsave(plot = veg_plot_custom #tell ggsave which plot to export #, filename = &quot;VegBiomass_TimeSeries_FrenchIsland.png&quot; #provide the name for the image file # , width = 6, height =4, units = &quot;in&quot; #dimensions of the exported image # , dpi = 300 #resolution of the image (dots per inch) # ) "],["interactive-tools.html", "Chapter 4 Interactive Tools 4.1 Plotly - Interactive plotting 4.2 Leaflet 4.3 Mapview", " Chapter 4 Interactive Tools Here are some tools to help with interactive viewing of data. We use plotly for visualizing data in gpplot, and leaflet and mapview for visualizing spatial data. 4.1 Plotly - Interactive plotting Load packages. library(ggplot2) library(lubridate) library(plotly) We are using the iris dataset that comes with R. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Make a plot. iris1 &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point() Use plotly to make plot interactive. You can draw a box around an area to zoom in, double click on plot to zoom back out. If you click on virginica in the legend it will remove that from the plot. ggplotly(iris1) You might want to change what shows up when you hover over the point. You can do this by adding the label parameter to your aes() call. iris2 &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species, label = Petal.Length)) + geom_point() ggplotly(iris2) If you want even more customization of what shows up, you can use the text parameter in your aes() call. You can then customize the combination of what shows up: x, y, text. Note  inserts a line break into your popup. iris3 &lt;- ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, text = paste(&#39;Name of species: &#39;, Species, &#39;&lt;br&gt;Petal length: &#39;, Petal.Length)))+ geom_point() # customize whether you want to display x, y, and text, or just text ggplotly(iris3) ggplotly(iris3, tooltip = &quot;text&quot;) ggplotly(iris3, tooltip = c(&quot;x&quot;, &quot;text&quot;)) If you dont want the popup at all, you can also get rid of it. # Use tooltip = NULL to get rid of all tooltip ggplotly(iris3, tooltip = NULL) Resources: * https://plotly.com/r/hover-text-and-formatting/ * https://stackoverflow.com/questions/36325154/how-to-choose-variable-to-display-in-tooltip-when-using-ggplotly 4.2 Leaflet library(readr) library(leaflet) library(viridis) library(dplyr) Lets use some station data from water temperature dataset. stations_URL &lt;- &quot;https://portal.edirepository.org/nis/dataviewer?packageid=edi.591.2&amp;entityid=a059f5eea4f8500fe1a43566451ec593&quot; stations &lt;- readr::read_csv(stations_URL) %&gt;% mutate(County = factor(County)) %&gt;% mutate(Temperature = runif(n = nrow(.), min = 8, max = 30)) # Add a column of made up temperature data dplyr::glimpse(stations) ## Rows: 138 ## Columns: 12 ## $ Station &lt;chr&gt; &quot;ANC&quot;, &quot;ANH&quot;, &quot;BAC&quot;, &quot;BDL&quot;, &quot;BDT&quot;, &quot;BET&quot;, &quot;BIR&quot;, &quot;BKS~ ## $ StationName &lt;chr&gt; &quot;ANTIOCH (USBR)&quot;, &quot;SAN JOAQUIN RIVER AT ANTIOCH&quot;, &quot;BA~ ## $ StartDateDataset &lt;date&gt; 1999-02-28, 1994-12-31, 2008-04-17, 2008-02-27, 2005~ ## $ EndDateDataset &lt;date&gt; 2016-06-09, 2017-07-20, 2016-11-30, 2017-12-27, 2008~ ## $ Agency &lt;chr&gt; &quot;USBR&quot;, &quot;DWR&quot;, &quot;DWR&quot;, &quot;DWR&quot;, &quot;DWR&quot;, &quot;DWR&quot;, &quot;DWR&quot;, &quot;DW~ ## $ Latitude &lt;dbl&gt; 38.01782, 38.01783, 37.96935, 38.18690, 37.86500, 38.~ ## $ Longitude &lt;dbl&gt; -121.8030, -121.8030, -121.5722, -121.9708, -121.3231~ ## $ HydrologicArea &lt;chr&gt; &quot;Sacramento River&quot;, &quot;Sacramento River&quot;, &quot;Sacramento R~ ## $ Basin &lt;chr&gt; &quot;Delta&quot;, &quot;San Joaquin R&quot;, &quot;Delta&quot;, &quot;Sacramento R&quot;, &quot;S~ ## $ County &lt;fct&gt; Contra Costa, Contra Costa, San Joaquin, Solano, San ~ ## $ HabitatType &lt;chr&gt; &quot;Tidal River Channel (brackish)&quot;, &quot;Tidal River Channe~ ## $ Temperature &lt;dbl&gt; 10.271113, 21.343277, 23.601055, 16.809101, 21.365530~ Define your color palette. How do you want to color your stations? # Let&#39;s say we are coloring by County. unique(stations$County) # There are 6 counties ## [1] Contra Costa San Joaquin Solano Sacramento Alameda ## [6] Yolo ## Levels: Alameda Contra Costa Sacramento San Joaquin Solano Yolo # We will pick 6 colors from the viridis package. pal &lt;- colorFactor(viridis::viridis(6), stations$County) You could alternatively use colorNumeric, colorBin, or colorQuantile as an argument. See https://rstudio.github.io/leaflet/colors.html Make your plot. stations %&gt;% # call data frame. leaflet() %&gt;% # call leaflet. addTiles() %&gt;% # this adds the map in the background. addCircleMarkers( color = ~pal(County), stroke = FALSE, # alters whether there is a border to circle fillOpacity = 0.8, lng = ~Longitude, # call your longitude column name lat = ~Latitude, # call you latitude column name label = ~paste(Station, &quot;Lat:&quot;, Latitude, &quot;Long:&quot;, Longitude)) %&gt;% # edit what you want to show up in your label addLegend(pal = pal, values = ~County, position = &quot;bottomright&quot;) If you want to change the radius of your points based on a variable, you can also do that. Define your palette colors again. In this example, we picked individual colors rather than using an existing palette, and assign them directly to each basin. unique(stations$Basin) # need 7 ## [1] &quot;Delta&quot; &quot;San Joaquin R&quot; &quot;Sacramento R&quot; &quot;East Bay&quot; ## [5] &quot;Mokelumne R&quot; &quot;Stanislaus R&quot; &quot;Cache Cr&quot; pal2 &lt;- colorFactor(c(&quot;purple3&quot;, &quot;blue3&quot;, &quot;forestgreen&quot;, &quot;orange&quot;, &quot;orangered&quot;, &quot;hotpink&quot;, &quot;grey&quot;), domain = c(&quot;Cache Cr&quot;, &quot;Delta&quot;, &quot;East Bay&quot;, &quot;Mokelumne R&quot;, &quot;Sacramento R&quot;, &quot;San Joaquin R&quot;, &quot;Stanislaus R&quot;)) Make map, this time defining the radius option. stations %&gt;% leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers( fillColor = ~pal2(Basin), radius = ~sqrt(Temperature), # modify the size of circles based on the temperature stroke = FALSE, fillOpacity = 0.6, lng = ~Longitude, lat = ~Latitude, label = ~paste(Station, &quot;Lat:&quot;, Latitude, &quot;Long:&quot;, Longitude, &quot;Temperature:&quot;, Temperature))%&gt;% addLegend(pal = pal2, values = ~Basin, position = &quot;topright&quot;) You can also have the labels be more permanent. See labelOptions below (noHide = T). If textOnly = FALSE, there will be a white box around your label. Doesnt work great for this plot, since there are so many stations. stations %&gt;% leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers( fillColor = ~pal2(Basin), radius = ~sqrt(Temperature), # modify the size of circles based on the temperature stroke = FALSE, fillOpacity = 0.6, lng = ~Longitude, lat = ~Latitude, label = ~Station, labelOptions = labelOptions(noHide = T, direction = &quot;right&quot;, textsize = &quot;7px&quot;, textOnly = TRUE))%&gt;% addLegend(pal = pal2, values = ~Basin, position = &quot;topright&quot;) There are other types of markers too. This is the default. stations %&gt;% leaflet() %&gt;% addTiles() %&gt;% addMarkers( lng = ~Longitude, lat = ~Latitude, label = ~Station) This is a square. stations %&gt;% leaflet() %&gt;% addTiles() %&gt;% addRectangles( lng1=min(stations$Longitude) - 0.1, lat1=min(stations$Latitude) -0.1 , lng2=max(stations$Longitude) +0.1, lat2=max(stations$Latitude) +0.1, fillColor = &quot;transparent&quot;, color = &quot;orangered&quot; ) %&gt;% addCircleMarkers( lng = ~Longitude, lat = ~Latitude, label = ~Station, radius = 2) 4.3 Mapview This one is a nice, simple way to just take a look at your points. library(mapview) library(sf) Convert your stations to a spatial object. # name the columns for longitude and latitude # crs is the WGS 1984 projection, which is usually the projection for lat/lon data stations_sf &lt;- sf::st_as_sf(stations, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) Just one line to see a decent plot! This one shows you all the associated data linked with each point. mapview(stations_sf) Color by variable of interest mapview(stations_sf, zcol = &quot;Basin&quot;) Size your variables mapview(stations_sf, zcol = &quot;Basin&quot;, cex = &quot;Temperature&quot;) "],["shiny.html", "Chapter 5 Shiny", " Chapter 5 Shiny "],["spatial-data-and-making-maps.html", "Chapter 6 Spatial data and making maps 6.1 Load data 6.2 Get data into spatial form 6.3 Basic Spatial Operations 6.4 Make maps 6.5 Basemaps", " Chapter 6 Spatial data and making maps We will cover: 1. Basics of using sf package, converting lat/lon to a spatial data frame. 2. Importing shapefiles 3. Making a map of your lats/lons 4. Add inset map 5. Add scale bar, north arrow, labels 6. Add basemap 7. Writing map image and map files Packages library(ggplot2) library(dplyr) library(sf) library(viridis) 6.1 Load data Latitude/Longitude data from IEP zooplankton data # Latitude/Longitude data stations_URL &lt;- &quot;https://portal.edirepository.org/nis/dataviewer?packageid=edi.539.3&amp;entityid=343cb43b41eb112ac36b605f1cff1f92&quot; # Create a fake n variable to have something to plot. stations &lt;- readr::read_csv(stations_URL) %&gt;% mutate(n = round(runif(n = 1:nrow(.), min = 1, max = 100),0)) %&gt;% mutate(Source = factor(Source)) %&gt;% filter(!is.na(Latitude)) dplyr::glimpse(stations) ## Rows: 368 ## Columns: 5 ## $ Source &lt;fct&gt; EMP, EMP, EMP, EMP, EMP, EMP, EMP, EMP, EMP, EMP, EMP, EMP, ~ ## $ Station &lt;chr&gt; &quot;NZ002&quot;, &quot;NZ003&quot;, &quot;NZ004&quot;, &quot;NZ005&quot;, &quot;NZ020&quot;, &quot;NZ022&quot;, &quot;NZ024~ ## $ Latitude &lt;dbl&gt; 38.06028, 38.05250, 38.02917, 38.03167, 38.05972, 38.07194, ~ ## $ Longitude &lt;dbl&gt; -122.2069, -122.1783, -122.1583, -122.1353, -122.1097, -122.~ ## $ n &lt;dbl&gt; 63, 63, 46, 80, 66, 81, 47, 92, 22, 21, 85, 51, 12, 5, 54, 9~ # create a subset of stations stationlist_filt &lt;- sample_n(stations, 20) %&gt;% select(Station) stationlist_filt &lt;- stationlist_filt$Station Shapefiles # Delta waterways library(deltamapr) plot(WW_Delta) glimpse(WW_Delta) ## Rows: 282 ## Columns: 10 ## $ AREA &lt;dbl&gt; 73544304.00, 87637.30, 7915130.00, 103906.00, 106371.00, 15~ ## $ PERIMETER &lt;dbl&gt; 1033340.000, 3319.230, 87427.898, 2718.730, 2798.310, 3391.~ ## $ HYDRO_POLY &lt;int&gt; 791, 1965, 1967, 1970, 1977, 1982, 1992, 2001, 2006, 2008, ~ ## $ HYDRO_PO_1 &lt;int&gt; 797, 1963, 1965, 1969, 1974, 1978, 1989, 2008, 2012, 2011, ~ ## $ HYDRO_24K_ &lt;int&gt; 798, 1964, 1966, 1970, 1975, 1979, 1990, 2009, 2013, 2012, ~ ## $ TYPE &lt;chr&gt; &quot;MR&quot;, &quot;S&quot;, &quot;C&quot;, &quot;L&quot;, &quot;L&quot;, &quot;S&quot;, &quot;S&quot;, &quot;MR&quot;, &quot;MR&quot;, &quot;MR&quot;, &quot;MR&quot;,~ ## $ HNAME &lt;chr&gt; &quot;SACRAMENTO RIVER&quot;, &quot;W&quot;, &quot;SACTO. R DEEP WATER SH CHAN&quot;, &quot;GR~ ## $ Shape_Leng &lt;dbl&gt; 2.448454165, 0.035719722, 0.828813375, 0.026377690, 0.02830~ ## $ Shape_Area &lt;dbl&gt; 3.476418e-03, 9.063090e-06, 8.166341e-04, 1.074391e-05, 1.0~ ## $ geometry &lt;POLYGON [°]&gt; POLYGON ((-121.5099 38.2471..., POLYGON ((-121.5673~ # Regions Regions &lt;- deltamapr::R_EDSM_Subregions_Mahardja_FLOAT plot(Regions) glimpse(Regions) ## Rows: 40 ## Columns: 4 ## $ SubRegion &lt;chr&gt; &quot;Cache Slough and Lindsey Slough&quot;, &quot;Carquinez Strait&quot;, &quot;Conf~ ## $ SQM &lt;dbl&gt; 471689278, 48215634, 39171738, 182085789, 94761329, 23726124~ ## $ Region &lt;chr&gt; &quot;North&quot;, &quot;Far West&quot;, &quot;West&quot;, &quot;South&quot;, &quot;South&quot;, &quot;South&quot;, &quot;Wes~ ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((611964 4246976, 6..., POLYGON ((567190.8 4~ # States library(USAboundaries) California_sf &lt;- us_states(states = &quot;California&quot;) plot(California_sf[1]) 6.2 Get data into spatial form # Define the projection of your points, usually WGS 84 (= crs 4326) stations_sf &lt;- st_as_sf(stations, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) # Look at shapefile head(stations_sf) ## Simple feature collection with 6 features and 3 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -122.2069 ymin: 38.02917 xmax: -122.0961 ymax: 38.07194 ## Geodetic CRS: WGS 84 ## # A tibble: 6 x 4 ## Source Station n geometry ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;POINT [°]&gt; ## 1 EMP NZ002 63 (-122.2069 38.06028) ## 2 EMP NZ003 63 (-122.1783 38.0525) ## 3 EMP NZ004 46 (-122.1583 38.02917) ## 4 EMP NZ005 80 (-122.1353 38.03167) ## 5 EMP NZ020 66 (-122.1097 38.05972) ## 6 EMP NZ022 81 (-122.0961 38.07194) plot(stations_sf$geometry) plot(stations_sf) 6.2.1 Spatial projections You want to make sure all your different files are in the same projection, or they will look mis-aligned. st_crs(WW_Delta) # In 4269 ## Coordinate Reference System: ## User input: NAD83 ## wkt: ## GEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;latitude&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;longitude&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]] st_crs(stations_sf) # In 4326 ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic latitude (Lat)&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic longitude (Lon)&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## USAGE[ ## SCOPE[&quot;Horizontal component of 3D system.&quot;], ## AREA[&quot;World.&quot;], ## BBOX[-90,-180,90,180]], ## ID[&quot;EPSG&quot;,4326]] st_crs(California_sf) # In 4326 ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic latitude (Lat)&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic longitude (Lon)&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## USAGE[ ## SCOPE[&quot;Horizontal component of 3D system.&quot;], ## AREA[&quot;World.&quot;], ## BBOX[-90,-180,90,180]], ## ID[&quot;EPSG&quot;,4326]] stations_4269 &lt;- st_transform(stations_sf, crs = 4269) california_4269 &lt;- st_transform(California_sf, crs = 4269) 6.3 Basic Spatial Operations Assign points to regions Nearest neighbor Intersections 6.4 Make maps 6.4.1 Basic maps Color by Monitoring Program ggplot() + geom_sf(data = WW_Delta) + geom_sf(data = stations_4269, aes(fill = Source), shape = 21) + scale_fill_viridis(discrete = TRUE) + ggtitle(&quot;Number of Zooplankton Samples by Station&quot;) + theme_bw() You can also modify the size of the points by size # Making a smaller dataset stations_filtered_4269 &lt;- stations_4269 %&gt;% filter(Station %in% stationlist_filt) (simplemap &lt;- ggplot() + geom_sf(data = WW_Delta, fill = &quot;lightblue&quot;, color = &quot;lightblue&quot;) + geom_sf(data = stations_filtered_4269, aes(fill = Source, size = n), shape = 21, alpha = 0.7) + scale_fill_viridis(discrete = TRUE, option = &quot;plasma&quot;) + scale_size_continuous(range = c(0,3)) + ggtitle(&quot;Number of Zooplankton Samples by Station&quot;) + theme_bw()) You can add region delineations as well ggplot() + geom_sf(data = WW_Delta, fill = &quot;lightblue&quot;, color = &quot;lightblue&quot;) + geom_sf(data = Regions, aes(color = Region), alpha = 0.3) + geom_sf(data = stations_filtered_4269, aes(fill = Source, size = n), shape = 21) + scale_fill_viridis(discrete = TRUE, option = &quot;plasma&quot;) + scale_color_viridis(discrete = TRUE, option = &quot;turbo&quot;) + scale_size_continuous(range = c(0,3)) + ggtitle(&quot;Number of Zooplankton Samples by Station&quot;) + theme_bw() 6.4.2 Add arrows and scale bars, dotted lines require(ggspatial) # https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html (simplemap2 &lt;- simplemap + annotation_north_arrow(location = &quot;tr&quot;, which_north = &quot;true&quot;, pad_x = unit(0.1, &quot;in&quot;), pad_y = unit(0.1, &quot;in&quot;), style = north_arrow_fancy_orienteering) + annotation_scale(location = &quot;bl&quot;, bar_cols = c(&quot;pink&quot;, &quot;white&quot;, &quot;pink&quot;, &quot;white&quot;)) + theme(axis.title = element_blank(), panel.grid.major = element_line(color = &quot;grey80&quot;, linetype = &quot;dashed&quot;, size = 0.5))) 6.4.3 Add labels to map # Adding text simplemap2 + geom_text(data = filter(stations, Station %in% stationlist_filt), aes(x = Longitude, y = Latitude, label = Station), size = 2, check_overlap = FALSE, color = &quot;darkblue&quot;, nudge_x = 0.02, nudge_y = 0.02) + annotate(geom = &quot;text&quot;, x = -122.4, y = 37.85, label = &quot;San Francisco Bay&quot;, fontface = &quot;italic&quot;, color = &quot;grey22&quot;, size = 3.5 ) 6.4.4 Add inset map # Figure out boundary box for your stations; perhaps add a small buffer insetbbox0 = st_as_sfc(st_bbox(WW_Delta)) insetbbox = st_buffer(insetbbox0, 0.2) (inset &lt;- ggplot() + geom_sf(data = california_4269, fill = &quot;white&quot;) + geom_sf(data = insetbbox0, fill = NA, color = &quot;red&quot;, size = 0.5) + theme_void()) Combine main map with inset map Will need to play with where you want the inset to be so as not to overlap with your map library(cowplot) inset_map = ggdraw() + draw_plot(simplemap2) + draw_plot(inset, x = 0.15, y = 0.63, width = 0.3, height = 0.3) inset_map 6.5 Basemaps Download basemaps from get_stamenmap library(ggmap) Define coordinate bounding box. You could also use lat/lon if you want. buffer = 0.2 coordDict = list( &#39;minLat&#39; = min(stations$Latitude) - buffer, &#39;maxLat&#39; = max(stations$Latitude) -0.1, &#39;minLon&#39; = min(stations$Longitude) - buffer, &#39;maxLon&#39; = max(stations$Longitude) + buffer ) # Create map object using your bounded coordinates map_obj &lt;- get_stamenmap( bbox = c(left = coordDict[[&#39;minLon&#39;]], bottom = coordDict[[&#39;minLat&#39;]], right = coordDict[[&#39;maxLon&#39;]], top = coordDict[[&#39;maxLat&#39;]]), # the bounding box zoom = 9, # zoom lvl; higher number = more detail (but also more processing power) maptype = &#39;terrain-background&#39;# type of basemap; &#39;terrain&#39; is my default, but check help(get_stamenmap) for a full list ) Plot your basemap # Plot the map map &lt;- ggmap(map_obj, legend = &quot;right&quot;) map Add basemap to earlier map. map2 &lt;- ggmap(map_obj) + geom_sf(data = WW_Delta, fill = &quot;lightblue&quot;, color = &quot;lightblue&quot;, inherit.aes = FALSE) + geom_sf(data = stations_filtered_4269, aes(fill = Source), shape = 21, alpha = 0.7, size = 2.5, inherit.aes = FALSE) + annotate(geom = &quot;text&quot;, x = -122.4, y = 37.85, label = &quot;San Francisco Bay&quot;, fontface = &quot;italic&quot;, color = &quot;grey22&quot;, size = 3.5 ) + annotation_north_arrow(location = &quot;tr&quot;, which_north = &quot;true&quot;, pad_x = unit(0.1, &quot;in&quot;), pad_y = unit(0.1, &quot;in&quot;), style = north_arrow_fancy_orienteering) + annotation_scale(location = &quot;bl&quot;, bar_cols = c(&quot;black&quot;, &quot;white&quot;, &quot;black&quot;, &quot;white&quot;)) + scale_fill_viridis(discrete = TRUE, option = &quot;plasma&quot;) + ggtitle(&quot;Number of Zooplankton Samples by Station&quot;) + theme_bw()+ theme(axis.title = element_blank(), panel.grid.major = element_line(color = &quot;grey80&quot;, linetype = &quot;dashed&quot;, size = 0.5)) map2 "],["functions.html", "Chapter 7 Functions", " Chapter 7 Functions "],["for-loops-and-conditionals.html", "Chapter 8 For Loops and Conditionals 8.1 For Loops 8.2 Conditionals", " Chapter 8 For Loops and Conditionals 8.1 For Loops 8.2 Conditionals "],["data-exploration-and-qaqc.html", "Chapter 9 Data Exploration and QA/QC 9.1 1 Recommended Reference Material 9.2 2 Background 9.3 3 Prepare your data 9.4 4 Examine patterns and relationships between response and predictor 9.5 5 Identifying Outliers 9.6 6 Other QA/QC 9.7 7 References", " Chapter 9 Data Exploration and QA/QC 9.1 1 Recommended Reference Material There are probably many references for exploring your data. I dont necessarily follow any particular reference, but rather try a few different kinds of plots to pull out different aspects of the data. Depending on the analysis you are doing, you will also probably want to do some different kinds of exploration. Two sources I have used, however, are (Zuur et al. 2009), which includes some steps for data exploration prior to launching into mixed effects modeling (Chapter 2 and Appendix A), and (Wickham and Grolemund 2017), which has some useful information about visualizing data and exploratory data analysis, as well as other information about coding in the tidyverse (see below for description of the tidyverse). 9.2 2 Background Data exploration often occurs at multiple stages of an analysis. The initial data exploration is important for finding the issues with your data, and for getting an idea of what analyses you can perform. This training will include some examples of plots and code to help you look at the relationships between variables, including: Data over time Data over space Variability of data Collinearity Distribution of data How balanced your data are Missing data Outliers I will be conducting the majority of my data exploration using the tidyverse. The tidyverse is a collection of packages that use similar coding language to do things such as filter, reformat, manipulate, plot your code. You can call all the tidyverse packages using library(tidyverse). There are also many ways to conduct data exploration using base R and other packages. 9.3 3 Prepare your data Load packages # Clear your environment rm(list=ls(all=TRUE)) library(readr) # Read in data library(dplyr) # Manipulate data library(tidyr) # Pivot data library(lubridate) # Datetimes library(plotly) # Interactive plotting library(psych) # Correlation plots library(viridis) # Color palettes library(ODWGtools) # Tukey and MAD tests library(leaflet) # Interactive maps library(ggpubr) # dotplot #source(&quot;corvif.R&quot;) # From Zuur et al. 2009 for calculating VIF Create a theme to make font sizes slightly bigger for plots. I have put in an option to rotate the x-axis text when needed (degree = 90 in those cases) theme_plots &lt;- function(degree = 0) { theme_bw() + theme(axis.text.x = element_text(size = 14, angle = degree), axis.text.y = element_text(size = 14), axis.title.x = element_text(size = 15), axis.title.y = element_text(size = 15), legend.text = element_text(size = 14), strip.text = element_text(size = 11)) } 9.3.1 Get data Lets work with DWRs Yolo Bypass Fish Monitoring Programs Beach Seine (fish) data, which contains both water quality and fish data.This is available on EDI, but I saved a version of it for the training. Here is code below if you want to read the whole dataset from EDI. # Get URLs from EDI # URL_fish &lt;- &quot;https://portal.edirepository.org/nis/dataviewer?packageid=edi.233.2&amp;entityid=015e494911cf35c90089ced5a3127334&quot; # Read in data # fishData &lt;- readr::read_csv(URL_fish,show_col_types = FALSE)%&gt;% # dplyr::filter(MethodCode == &quot;BSEIN&quot;) # Write data # saveRDS(fishData, &quot;ybfmp_fishdata.rds&quot;) Start here if data are already downloaded. # Read data fishData &lt;- readRDS(&quot;data/ybfmp_fishdata.rds&quot;) 9.3.2 Develop your questions Before you explore, you may want to think about what your analysis questions will be to help you set up your data properly. What is/are your response variable(s)? What is/are your predictor variable(s)? You will likely need to do some data manipulation to get your data into the format you want for your questions. You can explore the data to figure out if its already set up correctly, or if you need to manipulate it to be analyzing correctly. For examples, lets say your question is: Is native fish abundance correlated with space, time, and water quality? Youll want to have the appropriate time, space, abundance metrics. Take a look at how R is seeing the data. It is important to make sure the class (e.g. character, factor double, logical, datetime) is correct when you analyze your data, otherwise you may run into errors: glimpse(fishData) ## Rows: 87,295 ## Columns: 32 ## $ SampleDate &lt;chr&gt; &quot;1/16/1998&quot;, &quot;1/16/1998&quot;, &quot;1/30/1998&quot;, &quot;1/30/1998~ ## $ SampleTime &lt;time&gt; 14:05:00, 15:00:00, 13:50:00, 13:50:00, 13:50:00~ ## $ StationCode &lt;chr&gt; &quot;YB&quot;, &quot;YB&quot;, &quot;YB&quot;, &quot;YB&quot;, &quot;YB&quot;, &quot;YB&quot;, &quot;YB&quot;, &quot;YB&quot;, &quot;~ ## $ MethodCode &lt;chr&gt; &quot;BSEIN&quot;, &quot;BSEIN&quot;, &quot;BSEIN&quot;, &quot;BSEIN&quot;, &quot;BSEIN&quot;, &quot;BSE~ ## $ GearID &lt;chr&gt; &quot;SEIN50&quot;, &quot;SEIN50&quot;, &quot;SEIN50&quot;, &quot;SEIN50&quot;, &quot;SEIN50&quot;,~ ## $ CommonName &lt;chr&gt; &quot;Threadfin Shad&quot;, &quot;Inland Silverside&quot;, &quot;Inland Si~ ## $ GeneticallyConfirmed &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;~ ## $ GeneticID &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ Field_ID_CommonName &lt;chr&gt; &quot;Threadfin Shad&quot;, &quot;Inland Silverside&quot;, &quot;Inland Si~ ## $ ForkLength &lt;dbl&gt; 90, 73, 56, 59, 39, 50, 37, 40, 49, 50, 22, 81, 4~ ## $ Count &lt;dbl&gt; 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1~ ## $ FishSex &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ Race &lt;chr&gt; &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;F&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n~ ## $ MarkCode &lt;chr&gt; &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, ~ ## $ CWTSample &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, ~ ## $ FishTagID &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ StageCode &lt;chr&gt; &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;n/p&quot;, &quot;CHN_P&quot;, &quot;n/p&quot;, &quot;n/p&quot;~ ## $ Dead &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;~ ## $ GearConditionCode &lt;dbl&gt; 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1~ ## $ WeatherCode &lt;chr&gt; &quot;CLD&quot;, &quot;CLD&quot;, &quot;CLD&quot;, &quot;CLD&quot;, &quot;CLD&quot;, &quot;CLD&quot;, &quot;CLD&quot;, ~ ## $ WaterTemperature &lt;dbl&gt; 11.66667, 11.66667, 12.22222, 12.22222, 12.22222,~ ## $ Secchi &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ Conductivity &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ SpCnd &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ DO &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ pH &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ Turbidity &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ SubstrateCode &lt;chr&gt; &quot;VG&quot;, &quot;MD&quot;, &quot;PV&quot;, &quot;PV&quot;, &quot;PV&quot;, &quot;PV&quot;, &quot;PV&quot;, &quot;PV&quot;, &quot;~ ## $ Tide &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ VolumeSeined &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ Latitude &lt;dbl&gt; 38.56538, 38.56538, 38.56538, 38.56538, 38.56538,~ ## $ Longitude &lt;dbl&gt; -121.631, -121.631, -121.631, -121.631, -121.631,~ head(fishData) ## # A tibble: 6 x 32 ## SampleDate SampleTime StationCode MethodCode GearID CommonName ## &lt;chr&gt; &lt;time&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1/16/1998 14:05 YB BSEIN SEIN50 Threadfin Shad ## 2 1/16/1998 15:00 YB BSEIN SEIN50 Inland Silverside ## 3 1/30/1998 13:50 YB BSEIN SEIN50 Inland Silverside ## 4 1/30/1998 13:50 YB BSEIN SEIN50 Inland Silverside ## 5 1/30/1998 13:50 YB BSEIN SEIN50 Chinook Salmon ## 6 1/30/1998 13:50 YB BSEIN SEIN50 Inland Silverside ## # ... with 26 more variables: GeneticallyConfirmed &lt;chr&gt;, GeneticID &lt;lgl&gt;, ## # Field_ID_CommonName &lt;chr&gt;, ForkLength &lt;dbl&gt;, Count &lt;dbl&gt;, FishSex &lt;chr&gt;, ## # Race &lt;chr&gt;, MarkCode &lt;chr&gt;, CWTSample &lt;lgl&gt;, FishTagID &lt;chr&gt;, ## # StageCode &lt;chr&gt;, Dead &lt;chr&gt;, GearConditionCode &lt;dbl&gt;, WeatherCode &lt;chr&gt;, ## # WaterTemperature &lt;dbl&gt;, Secchi &lt;dbl&gt;, Conductivity &lt;dbl&gt;, SpCnd &lt;dbl&gt;, ## # DO &lt;dbl&gt;, pH &lt;dbl&gt;, Turbidity &lt;dbl&gt;, SubstrateCode &lt;chr&gt;, Tide &lt;chr&gt;, ## # VolumeSeined &lt;dbl&gt;, Latitude &lt;dbl&gt;, Longitude &lt;dbl&gt; Response variable: Native fish CPUE Filter to relevant species, calculate daily CPUE (data currently by count, and broken up by species) Predictor variables: Water Year, Month, WQ, Station: You will want to extract datetime variables Filter to stations of interest 9.3.3 Manipulate data Here you will see me use %&gt;% fairly often. This is called a pipe and basically will allow you to continue running operations on the data frame called at the beginning, and let you avoid having to name multiple intermediate data frames. Below, I create a new data frame fishSeine that is based on the existing data frame fishData. Then I add/edit variables using mutate, filter data using filter, and select columns I dont want using select. See more about pipes and data manipulation functions in Wickham &amp; Grolemund 2017, Chapter 5. Add some datetime variables, make sure they are the right class. Filter beach seine data from 2010-2015. fishSeine &lt;- fishData %&gt;% #Calculate CPUE, add datetime variables mutate(CPUE = Count/VolumeSeined, Date = lubridate::mdy(SampleDate), Datetime = paste(Date, SampleTime), Datetime = lubridate::ymd_hms(Datetime), Year = lubridate::year(Date), fYear = factor(Year), Month = lubridate::month(Date), fMonth = factor(Month), WY = ifelse(Month &gt;9, Year + 1, Year), fWY = factor(WY))%&gt;% # Remove samples in bad condition, filter to a smaller timespan and station list filter(GearConditionCode &lt;3, Year&gt;2009 &amp; Year&lt;2016)%&gt;% # Remove variables not needed select(-SampleTime, -SampleDate, -GearID, -GearConditionCode, -MethodCode, -ForkLength, -GeneticallyConfirmed, -GeneticID, -Field_ID_CommonName, -FishSex, -MarkCode, -CWTSample, -StageCode, -Dead, -FishTagID, -Race, -SubstrateCode) Take a look at how the fish data are set up. For this dataset, only a certain number of fish are measured and the rest are counted. We want just one count per day, so this is done here. Many datasets only report on what they have caught, and not which species have not been caught. This can skew the CPUE if you are looking at averages by species. Here we fill in zeroes for species not caught. # Some more that needs to be done to fish counts fishSeineC &lt;- fishSeine %&gt;% # Sum to one count per species per datetime and station # (data not formatted this way since some fish have lengths and others do not) group_by(StationCode, Datetime, CommonName) %&gt;% mutate(Count2 = sum(Count), CPUE2 = sum(CPUE), Volume2 = sum(VolumeSeined)) %&gt;% ungroup() %&gt;% select(-Count, -CPUE, -VolumeSeined) %&gt;% distinct() %&gt;% rename(Count = Count2, CPUE = CPUE2, VolumeSeined = Volume2) %&gt;% arrange(CommonName) %&gt;% # Add zeroes in pivot_wider(names_from = CommonName, values_from = CPUE,values_fill = 0L) %&gt;% janitor::clean_names(., case = &quot;lower_camel&quot;) %&gt;% select(-noCatch) %&gt;% pivot_longer(cols = c(americanShad:yellowfinGoby), names_to = &quot;commonName&quot;, values_to = &quot;cpue&quot;) Lets reduce to just a few stations for now. # Filter out stations of interest fishSeineS &lt;- fishSeineC %&gt;% filter(stationCode %in% c(&quot;AL2&quot;,&quot;LI&quot;, &quot;BL2&quot;, &quot;BL4&quot;)) Create native species subset of data. nativespecies &lt;- c(&quot;chinookSalmon&quot;, &quot;splittail&quot;, &quot;sacramentoBlackfish&quot;, &quot;sacramentoPikeminnow&quot;, &quot;sacramentoSucker&quot;, &quot;hardhead&quot;, &quot;tulePerch&quot;, &quot;hitch&quot;) fishNative &lt;- filter(fishSeineS, commonName %in% nativespecies) Lets just have one CPUE for all fish per day. native fish of interest all fish # Filter to some natives fishCPUE_n &lt;- fishNative %&gt;% group_by(stationCode, date, year, fWy, fMonth) %&gt;% summarize(sumCPUE = sum(cpue)) %&gt;% ungroup() # All fish fishCPUE &lt;- fishSeineS %&gt;% group_by(stationCode, date, year, fWy, fMonth) %&gt;% summarize(sumCPUE = sum(cpue)) %&gt;% ungroup() Daily native fish CPUE for all stations (for spatial data examples) fishSeineNatives &lt;- fishSeineC %&gt;% filter(commonName %in% nativespecies) %&gt;% group_by(wy, date, stationCode, latitude, longitude) %&gt;% summarize(sumCPUE = sum(cpue)) %&gt;% filter(wy&gt;2011 &amp; wy&lt;2015) %&gt;% mutate(fWy = factor(wy), fMonth = factor(month(date))) fishAnnualNatives &lt;- fishSeineNatives %&gt;% group_by(fWy, stationCode, latitude, longitude) %&gt;% summarize(sumcpue = sum(sumCPUE), n = n()) Lets also separate water quality so we can look at these variables for outliers. I like to put my data in long (all parameters in one column, all values in one column) to look at lots of different variables at the same time. fish_WQ &lt;- fishSeineS %&gt;% select(date, year, fWy, fMonth, stationCode, waterTemperature, conductivity, do, pH, secchi, turbidity, latitude, longitude) %&gt;% distinct() %&gt;% mutate(samplingId = 1:nrow(.)) WQ_long &lt;- pivot_longer(fish_WQ, cols = waterTemperature:turbidity, names_to = &quot;parameter&quot;, values_to = &quot;value&quot;) %&gt;% mutate(index = 1:nrow(.)) head(WQ_long %&gt;%select(date, parameter, value), 10) ## # A tibble: 10 x 3 ## date parameter value ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2010-07-28 waterTemperature 27.2 ## 2 2010-07-28 conductivity 358 ## 3 2010-07-28 do 8.64 ## 4 2010-07-28 pH 8.12 ## 5 2010-07-28 secchi 0.140 ## 6 2010-07-28 turbidity NA ## 7 2011-07-12 waterTemperature 23.3 ## 8 2011-07-12 conductivity 587 ## 9 2011-07-12 do 6.33 ## 10 2011-07-12 pH 8.32 Combine summed CPUE data with variables. vars &lt;- left_join(fishCPUE, fish_WQ) %&gt;% select(fWy, fMonth, date, stationCode, sumCPUE, waterTemperature, conductivity, turbidity, secchi, do, pH, latitude, longitude) 9.4 4 Examine patterns and relationships between response and predictor We can use tables and plots to look at the data in different ways, and gather different types of information about your data and data structure. Grouping by different variables will help you identify outliers, gaps, and learn about your data. 9.4.1 A) Data over time Dotplots plot your data by row, which usually means it is plotted in order of time. This can be useful for finding outliers. dotchart(vars$sumCPUE, bg = &quot;springgreen4&quot;) You can also group by station (though so many values, it is hard to see) dotchart(vars$sumCPUE, labels = vars$stationCode, groups = vars$longitude, bg = viridis(4, option = &quot;magma&quot;)) Point plots basically flip this, and it is easy to color code by different variables. You can do this by date label. Here I have also added some lines at the beginning of each water year to help split the plot up. (Seine_pointplots &lt;- vars %&gt;% ggplot(aes(x= date, y = sumCPUE, color = stationCode)) + geom_point() + geom_vline(xintercept = as.Date(&quot;2010-10-01&quot;), linetype = &quot;dashed&quot;) + geom_vline(xintercept = as.Date(&quot;2011-10-01&quot;), linetype = &quot;dashed&quot;) + geom_vline(xintercept = as.Date(&quot;2012-10-01&quot;), linetype = &quot;dashed&quot;) + geom_vline(xintercept = as.Date(&quot;2013-10-01&quot;), linetype = &quot;dashed&quot;) + geom_vline(xintercept = as.Date(&quot;2014-10-01&quot;), linetype = &quot;dashed&quot;) + geom_vline(xintercept = as.Date(&quot;2015-10-01&quot;), linetype = &quot;dashed&quot;) + viridis::scale_color_viridis(discrete = TRUE, option = &quot;turbo&quot;) + scale_x_date(breaks = &quot;6 months&quot;) + theme_plots(90)) 9.4.2 B) Data over space If you have a lot of stations, it can be good to check your latitudes and longitudes are correct, get an idea of the area of the dataset, how you might want to divide up regions, etc., as well as a quick look at spatial trends, if that is one of your questions. Create a data frame of stations. stations &lt;- fishSeineNatives %&gt;% select(stationCode, longitude, latitude, sumCPUE) %&gt;% group_by(stationCode, longitude, latitude) %&gt;% filter(sumCPUE !=0) %&gt;% slice(1) %&gt;% # just picking one value per #station for this exercise. #slice picks the first value # for each station-lon-lat combo. mutate(sumCPUE = round(sumCPUE,3)) # round CPUE so it&#39;s not a crazy long number # when it pops up on leaflet. I am going to use the leaflet package here, which allows you to view your stations interactively. You can also view data associated with the station by using colors or size to visualize different variables. # Define your color palette by telling it what colors # to use for which variable. You will need one color per level. pal &lt;- colorFactor(viridis::turbo(13), stations$stationCode) # Make map stations %&gt;% leaflet() %&gt;% # call leaflet. addTiles() %&gt;% # this adds the map in the background. addCircleMarkers( color = ~pal(stationCode), stroke = FALSE, # alters whether there is a border to circle fillOpacity = 0.9, radius = ~sumCPUE*400, lng = ~longitude, # call your longitude column name lat = ~latitude, # call you latitude column name label = ~paste(stationCode, &quot; sumCPUE:&quot;, sumCPUE, &quot;Lat:&quot;, latitude, &quot;Long:&quot;, longitude)) %&gt;% # edit what you want to show up in your label addLegend(pal = pal, values = ~stationCode, position = &quot;bottomright&quot;) You can also look at some patterns in the data in ggplot. Here you might note that certain stations have greater CPUE across years while others fluctuate, and also that stations are not all sampled each year. ggplot(fishAnnualNatives, aes(longitude, latitude, size = sumcpue, color = stationCode), alpha = 0.5) + geom_jitter() + facet_wrap(~fWy) + scale_colour_viridis(option = &quot;turbo&quot;, discrete = TRUE)+ theme_plots(90) + theme(legend.text = element_text(size = 8)) + guides(colour = guide_legend(ncol = 3, byrow = T), size = guide_legend(ncol = 2)) 9.4.3 C) Variability of data and continuous-categorical relationships We can use boxplots to look at the variability of your continuous data by categorical variables, and also to identify major outliers. 9.4.3.1 By Station (Seine_boxplot &lt;- WQ_long %&gt;% ggplot(aes(x= stationCode, y = value, fill = stationCode)) + geom_boxplot() + facet_wrap(~parameter, scales = &quot;free&quot;) + viridis::scale_fill_viridis(discrete = TRUE, option = &quot;turbo&quot;) + theme_plots(90)) 9.4.3.2 By Water Year You might notice some different outliers when you look by year. You may also note some trends. (Seine_boxplots_WY &lt;- WQ_long %&gt;% ggplot(aes(x= fWy, y = value, fill = fWy)) + geom_boxplot() + facet_wrap(~parameter, scales = &quot;free&quot;) + viridis::scale_fill_viridis(discrete = TRUE, option = &quot;turbo&quot;) + theme_plots(90)) 9.4.3.3 By Station and Water Year (Seine_boxplots_month &lt;- WQ_long %&gt;% ggplot(aes(x= fWy, y = value, fill = stationCode)) + geom_boxplot() + facet_wrap(~parameter, scales = &quot;free&quot;) + viridis::scale_fill_viridis(discrete = TRUE, option = &quot;turbo&quot;) + theme_plots(90)) Boxplots are less useful for data with lots of zeroes, but can still pull out outliers. You could also plot fork length to look for outliers. (Fish_boxplots &lt;- fishSeineNatives %&gt;% ggplot(aes(x= factor(wy), y = sumCPUE, fill = factor(wy))) + geom_boxplot() + viridis::scale_fill_viridis(discrete = TRUE, option = &quot;turbo&quot;) + theme_plots(90)) 9.4.4 D) Collinearity and relationships between continuous variables Scatterplots are useful to look at relationships between continuous variables. These plots are useful: 1) to help you find outliers in variables that should be correlated 2) to help you see relationships that might be interesting to explore 3) to help determine whether certain variables may need to be removed for your model 9.4.4.1 Outlier detection Turbidity and Secchi, DO and Water Temperature should be correlated ggplot(vars,aes(turbidity, secchi)) + geom_point() + geom_smooth() + theme_plots() ggplot(vars,aes(do, waterTemperature)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + theme_plots() ggplot(vars,aes(do, waterTemperature)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~stationCode) + theme_plots() Some possible outliers or strange things happening with the high do/high water temperature values at AL2 9.4.4.2 Pairplots Pairplots and correlation coefficients are useful for identifying collinearity (variables that are correlated with each other) vars_filt &lt;- vars %&gt;% select(sumCPUE, waterTemperature, conductivity, secchi, turbidity, pH, do) (corr_plot &lt;- pairs.panels(vars_filt, hist.col = &quot;white&quot;, cex.cor = 1, pch = 21, stars = TRUE)) ## NULL 9.4.4.3 Variance Inflation Factor (VIF) VIF is another way to assess collinearity. This value indicates the ratio of variance in the entire model to the variance for a model with each individual variable. Higher vif indicates greater collinearity. If values are below 3, they are acceptable to be included together in a model. If values are above 3, Zuur et al. 2010 recommends sequentially removing variables with vif&gt;3 until all values are below 3. Other sources may have other cutoffs, and you may make your own determinations for what to include in a model. You can assess vif on a model using car::vif(). You can also run this corvif function (Zuur et al. 2009), which has been included as a separate file, or is available here: corvif function. Since we have not specified a model, I have used this function, which basically models the data in a linear model and calculates the vif. #corvif(vars_filt[,-1]) 9.4.5 E) Distribution of data We can use histograms to look at the distribution of the data, and can also find outliers this way. Here are some examples of distributions as a reference: Probability Distributions, from Rasmus 2018 Lets take a look at the distribution of native fishes vs. all fish. ggplot(fishCPUE_n, aes(sumCPUE)) + geom_histogram(binwidth = 0.1) + labs(title = &quot;Native Fish&quot;) + theme_plots() ggplot(fishCPUE, aes(sumCPUE)) + geom_histogram(binwidth = 0.1) + labs(title = &quot;All Fish&quot;) + theme_plots() You can also look at a histogram of sorts over multiple categories using a freqpoly plot. ggplot(fishCPUE, aes(sumCPUE, color = stationCode)) + geom_freqpoly(binwidth = 0.5) + labs(title = &quot;All Fish by Station&quot;) + theme_plots() Here you can see that there are a lot of zeroes in the data, especially for the native fishes. This can inform the type of model you will likely use down the line (e.g. zero-inflated poisson or negative binomial modeling) ggplot(WQ_long, aes(value)) + geom_histogram(color = &quot;navyblue&quot;, fill = &quot;steelblue4&quot;) + facet_wrap(~parameter, scales = &quot;free&quot;) + theme_plots() The distributions of the water quality data are quite different, some of them being normally distributed (e.g. do, pH), some of them being right-skewed (secchi, turbidity), some being left-skewed (waterTemperature), but none being quite as skewed as the fish data. When you analyze your data, you may want to transform and/or standardize some of your response or predictor variables, depending on the analysis. Transformations may help make your data normal, which would allow you to use several parametric analyses. See transformed turbidity below. par(mfrow = c(1,2)) hist(fish_WQ$turbidity, main = &quot;Turbidity&quot;) hist(log(fish_WQ$turbidity), main = &quot;Log-transformed Turbidity&quot;, col = &quot;steelblue4&quot;) 9.4.6 F) How balanced are your data? Often you want to have a balanced design (similar number of samples across treatments). Thus, it is useful to look at how your sample numbers are distributed across treatments. fishCPUE %&gt;% count(stationCode) ## # A tibble: 4 x 2 ## stationCode n ## &lt;chr&gt; &lt;int&gt; ## 1 AL2 119 ## 2 BL2 122 ## 3 BL4 126 ## 4 LI 28 There is much less data in LI. You may look to see in metadata or datasheets whether this should be the case. You can also look at this visually - note not all stations measured the same each year lessSta &lt;- fishAnnualNatives %&gt;% filter(!stationCode %in% c(&quot;AL2&quot;, &quot;AL4&quot;, &quot;BL2&quot;, &quot;BL4&quot;)) ggplot(lessSta, aes(longitude, latitude, size = n, fill = stationCode))+ geom_point(alpha = 0.9, shape = 21, color = &quot;black&quot;) + facet_wrap(~fWy) + scale_fill_viridis(option = &quot;turbo&quot;, discrete = TRUE) + theme_plots(90) + theme(legend.text = element_text(size = 8)) + guides(fill = guide_legend(ncol = 2, byrow = T), size = guide_legend(ncol = 2)) 9.4.7 G) Are there missing data? A tile plot can be useful in identifying gaps in data. samples &lt;- vars %&gt;% group_by(stationCode, fWy, fMonth) %&gt;% summarize(n = n()) ggplot(samples, aes(x = fWy, y = fMonth, fill = n)) + geom_tile() + facet_wrap(~stationCode) + theme_plots(90) LI does not have data in later years, there are some missing months that might need to be checked. 9.5 5 Identifying Outliers You could spend an entire lesson on QA/QC and outlier detection. In fact we have an entire working group at DWR dedicated to providing recommendations for outlier detection. I will just provide here some simple outlier tests here. I usually do a scan of the data (as in plots above), in addition to running some tests. To visually identify outliers to flag I like using a combination of the package plotly and point plots. With plotly, you can hover over points that are questionable to get more information on that point. You can change what shows up in the hover by editing the text option in your ggplot() call. It is very easy to use plotly, as you can just create your plot, then use ggplotly(nameofplot) to turn it into an interactive plot. Make normal plot. (Seine_pointplots &lt;- WQ_long %&gt;% ggplot(aes(x= date, y = value, color = stationCode, text = paste(&quot;index:&quot;, index, &quot;samplingID:&quot;, samplingId))) + geom_point(size = 0.5) + facet_wrap(~parameter, scales = &quot;free&quot;) + viridis::scale_color_viridis(discrete = TRUE, option = &quot;turbo&quot;) + theme_plots(90)) Use plotly to hover over variables (see R script) ggplotly(Seine_pointplots) There isnt anything too alarming here, but you might take a look at the pH swings happening in 2012 that might indicate pH sensor malfunction. You can identify the index by hovering or filter out values that are below or above certain thresholds and check these against your initial data source pH_flagID &lt;- WQ_long %&gt;% filter(parameter == &quot;pH&quot; &amp; (value &lt;7.5 | value&gt;9.1)) head(pH_flagID) ## # A tibble: 6 x 11 ## date year fWy fMonth stationCode latitude longitude samplingId ## &lt;date&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2015-07-09 2015 2015 7 BL4 38.4 -122. 14 ## 2 2010-01-04 2010 2010 1 LI 38.5 -122. 18 ## 3 2010-04-07 2010 2010 4 LI 38.5 -122. 21 ## 4 2010-09-15 2010 2010 9 BL4 38.4 -122. 28 ## 5 2010-09-15 2010 2010 9 BL2 38.4 -122. 29 ## 6 2010-09-30 2010 2010 9 AL2 38.5 -122. 30 ## # ... with 3 more variables: parameter &lt;chr&gt;, value &lt;dbl&gt;, index &lt;int&gt; You can also use a Cleveland dotplot to identify the range of values and whether there are obvious outliers. vars_filt$index = row.names(vars_filt) ggdotchart(data = vars_filt, x= &quot;index&quot;, y = &quot;sumCPUE&quot;, rotate = T) 9.5.1 A) Tukey Outliers These are how boxplots, and also Tukey test outliers, are identified. Boxplot outliers, from Grolemund &amp; Wickham 2017 9.5.2 B) Median Absolute Deviation Outliers The median absolute deviation is similar to a z-score, but centering calculations around the median rather than the mean for less bias of very high or low values. d = Calculate the deviation between xi - median(x) med_d = median(d) mad = med_d * 1.4826 scores_d = d/mad If scores_d &gt; 1.5, it is considered an outlier. This is similar to the number of standard deviations greater than the mean. 9.5.3 C) Run outlier tests DWR has an Outlier Detection Working Group that has coded a few outlier tests. To install, run the code below: install.packages(&quot;remotes&quot;) remotes::install_github(&quot;ODWG/ODWGtools&quot;) library(ODWGtools) outliers &lt;- WQ_long %&gt;% group_by(parameter) %&gt;% mutate(MAD = ODWGtools::outlier_mad(value), Tukey = ODWGtools::outlier_tukey(value)) %&gt;% mutate(MAD = ifelse(is.na(MAD), &quot;not outlier&quot;, as.character(MAD)), Tukey = ifelse(is.na(Tukey), &quot;not outlier&quot;, as.character(Tukey)) ) head(outliers %&gt;% select(date, value, MAD, Tukey)) ## # A tibble: 6 x 5 ## # Groups: parameter [6] ## parameter date value MAD Tukey ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 waterTemperature 2010-07-28 27.2 not outlier not outlier ## 2 conductivity 2010-07-28 358 not outlier not outlier ## 3 do 2010-07-28 8.64 not outlier not outlier ## 4 pH 2010-07-28 8.12 not outlier not outlier ## 5 secchi 2010-07-28 0.140 not outlier not outlier ## 6 turbidity 2010-07-28 NA not outlier not outlier You can use the output to decide on flags. Sometimes these tests can be too sensitive, but it is a quantitative way to determine outliers. ggplot(outliers) + geom_point(aes(x = date, y = value, color = Tukey, shape = MAD)) + facet_wrap(~parameter, scales = &quot;free&quot;) + scale_color_viridis(discrete = TRUE, option = &quot;turbo&quot;) + theme_plots(90) 9.5.4 D) Treatment of outliers Some options once you find outliers is to: Flag them and leave data as is (e.g. 1 = acceptable, 2 = suspicious, 3 = highly suspicious) - useful if you are providing data for others If you are analyzing data you will want to then either: Remove outliers (replace with NA) Replace outliers (with a mean, with data from another source, with interpolated value, with value before or after) 9.6 6 Other QA/QC Some other things you might want to check are: Variable names and factor levels are consistent (sometimes there is a mis-spelling or wrong case that creates an extra level in your factor) Values are within absolute ranges or thresholds (e.g. in a given system, you probably have an approximation of minimum and maximum reasonable temperatures.) Check zeros to make sure they are accurate, and not defaulted for an NA or blank entry. For outlier detection with continuous data, check out other tests in ODWGTools, NOAA manuals at IOOS Site, or reach out to the Outlier Detection Working Group for more guidance. 9.7 7 References Grolemund, G., &amp; Wickham, H. (2017). R for Data Science. OReilly Media. https://r4ds.had.co.nz/index.html Interagency Ecological Program (IEP), B. Schreier, B. Davis, and N. Ikemiyagi. 2019. Interagency Ecological Program: Fish catch and water quality data from the Sacramento River floodplain and tidal slough, collected by the Yolo Bypass Fish Monitoring Program, 1998-2018. ver 2. Environmental Data Initiative. https://doi.org/10.6073/pasta/b0b15aef7f3b52d2c5adc10004c05a6f (Accessed 2022-02-28). Rasmus, B. Distribution_diagrams (2018). GitHub Repository. https://github.com/rasmusab/distribution_diagrams) Qartod* Zuur A.F., Ieno E.N., Walker N.J., Saveliev A.A, Smith G.M. (2009). Mixed Effects Models and Extensions in Ecology with R. Zuur A.F., Ieno E.N., Elphick C.S. (2010). A protocol for data exploration to avoid common statistical problems. Methods in Ecology and Evolution (1 (1), 3-14). https://doi.org/10.1111/j.2041-210X.2009.00001.x "],["basic-stats.html", "Chapter 10 Basic Stats 10.1 Parametric Stats 10.2 Non-parametric Statistics", " Chapter 10 Basic Stats fish_yolo_url &lt;- &quot;https://portal.edirepository.org/nis/dataviewer?packageid=edi.233.2&amp;entityid=015e494911cf35c90089ced5a3127334&quot; fish_data &lt;- readr::read_csv(fish_yolo_url) str(fish_data) ## spec_tbl_df [182,414 x 32] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ SampleDate : chr [1:182414] &quot;1/16/1998&quot; &quot;1/16/1998&quot; &quot;1/19/1998&quot; &quot;1/19/1998&quot; ... ## $ SampleTime : &#39;hms&#39; num [1:182414] 14:05:00 15:00:00 12:17:00 12:17:00 ... ## ..- attr(*, &quot;units&quot;)= chr &quot;secs&quot; ## $ StationCode : chr [1:182414] &quot;YB&quot; &quot;YB&quot; &quot;YB&quot; &quot;YB&quot; ... ## $ MethodCode : chr [1:182414] &quot;BSEIN&quot; &quot;BSEIN&quot; &quot;FNET&quot; &quot;FNET&quot; ... ## $ GearID : chr [1:182414] &quot;SEIN50&quot; &quot;SEIN50&quot; &quot;FKNT&quot; &quot;FKNT&quot; ... ## $ CommonName : chr [1:182414] &quot;Threadfin Shad&quot; &quot;Inland Silverside&quot; &quot;Threadfin Shad&quot; &quot;Chinook Salmon&quot; ... ## $ GeneticallyConfirmed: chr [1:182414] &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;No&quot; ... ## $ GeneticID : logi [1:182414] NA NA NA NA NA NA ... ## $ Field_ID_CommonName : chr [1:182414] &quot;Threadfin Shad&quot; &quot;Inland Silverside&quot; &quot;Threadfin Shad&quot; &quot;Chinook Salmon&quot; ... ## $ ForkLength : num [1:182414] 90 73 88 38 71 62 58 50 81 49 ... ## $ Count : num [1:182414] 1 1 1 1 1 1 1 1 1 1 ... ## $ FishSex : chr [1:182414] NA NA NA NA ... ## $ Race : chr [1:182414] &quot;n/p&quot; &quot;n/p&quot; &quot;n/p&quot; &quot;n/p&quot; ... ## $ MarkCode : chr [1:182414] &quot;n/p&quot; &quot;n/p&quot; &quot;n/p&quot; &quot;n/p&quot; ... ## $ CWTSample : logi [1:182414] FALSE FALSE FALSE FALSE FALSE FALSE ... ## $ FishTagID : chr [1:182414] NA NA NA NA ... ## $ StageCode : chr [1:182414] &quot;n/p&quot; &quot;n/p&quot; &quot;n/p&quot; &quot;CHN_P&quot; ... ## $ Dead : chr [1:182414] &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;No&quot; ... ## $ GearConditionCode : num [1:182414] 3 3 1 1 1 1 1 1 1 1 ... ## $ WeatherCode : chr [1:182414] &quot;CLD&quot; &quot;CLD&quot; &quot;RAN&quot; &quot;RAN&quot; ... ## $ WaterTemperature : num [1:182414] 11.7 11.7 11.1 11.1 11.1 ... ## $ Secchi : num [1:182414] NA NA 0.16 0.16 0.07 ... ## $ Conductivity : num [1:182414] NA NA NA NA NA NA NA NA NA NA ... ## $ SpCnd : num [1:182414] NA NA NA NA NA NA NA NA NA NA ... ## $ DO : num [1:182414] NA NA NA NA NA NA NA NA NA NA ... ## $ pH : num [1:182414] NA NA NA NA NA NA NA NA NA NA ... ## $ Turbidity : num [1:182414] NA NA NA NA NA NA NA NA NA NA ... ## $ SubstrateCode : chr [1:182414] &quot;VG&quot; &quot;MD&quot; NA NA ... ## $ Tide : chr [1:182414] NA NA NA NA ... ## $ VolumeSeined : num [1:182414] NA NA NA NA NA NA NA NA NA NA ... ## $ Latitude : num [1:182414] 38.6 38.6 NA NA NA ... ## $ Longitude : num [1:182414] -122 -122 NA NA NA ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. SampleDate = col_character(), ## .. SampleTime = col_time(format = &quot;&quot;), ## .. StationCode = col_character(), ## .. MethodCode = col_character(), ## .. GearID = col_character(), ## .. CommonName = col_character(), ## .. GeneticallyConfirmed = col_character(), ## .. GeneticID = col_logical(), ## .. Field_ID_CommonName = col_character(), ## .. ForkLength = col_double(), ## .. Count = col_double(), ## .. FishSex = col_character(), ## .. Race = col_character(), ## .. MarkCode = col_character(), ## .. CWTSample = col_logical(), ## .. FishTagID = col_character(), ## .. StageCode = col_character(), ## .. Dead = col_character(), ## .. GearConditionCode = col_double(), ## .. WeatherCode = col_character(), ## .. WaterTemperature = col_double(), ## .. Secchi = col_double(), ## .. Conductivity = col_double(), ## .. SpCnd = col_double(), ## .. DO = col_double(), ## .. pH = col_double(), ## .. Turbidity = col_double(), ## .. SubstrateCode = col_character(), ## .. Tide = col_character(), ## .. VolumeSeined = col_double(), ## .. Latitude = col_double(), ## .. Longitude = col_double() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; fish_lmb &lt;- fish_data %&gt;% filter(CommonName == &quot;Largemouth Bass&quot;) fish_lmb2 &lt;- fish_lmb %&gt;% filter(MethodCode %in% c(&quot;BSEIN&quot;, &quot;RSTR&quot;)) 10.1 Parametric Stats 10.1.1 T-test ### 1. Independent-samples t-test: Is there a difference in LMB Count by Method? ---------------- (lmb.ttest &lt;- t.test(fish_lmb2$Count~fish_lmb2$MethodCode)) # not significant ## ## Welch Two Sample t-test ## ## data: fish_lmb2$Count by fish_lmb2$MethodCode ## t = -2.4938, df = 372.14, p-value = 0.01307 ## alternative hypothesis: true difference in means between group BSEIN and group RSTR is not equal to 0 ## 95 percent confidence interval: ## -1.6055186 -0.1898624 ## sample estimates: ## mean in group BSEIN mean in group RSTR ## 1.146387 2.044077 # Plot ggplot(fish_lmb2, aes(x = MethodCode, y = Count)) + geom_boxplot() ggplot(fish_lmb2, aes(x = Count, color = MethodCode)) + geom_density() ggplot(fish_lmb, aes(x = MethodCode, y = Count)) + geom_col() # This works best for data with lots of zeros ### 2. Paired t-test: Does a treatment cause a difference? Did Action Phase alter Count of LMB? ------------- (lmb.ttest2 &lt;- t.test(fish_lmb2$Count ~ fish_lmb2$MethodCode)) # significant ## ## Welch Two Sample t-test ## ## data: fish_lmb2$Count by fish_lmb2$MethodCode ## t = -2.4938, df = 372.14, p-value = 0.01307 ## alternative hypothesis: true difference in means between group BSEIN and group RSTR is not equal to 0 ## 95 percent confidence interval: ## -1.6055186 -0.1898624 ## sample estimates: ## mean in group BSEIN mean in group RSTR ## 1.146387 2.044077 # Plot: Figure out the direction of the trend # ggplot(fish_lmb2, aes(x = ActionPhase, y = Count)) + geom_boxplot() # ggplot(fish_lmb2, aes(x = Count, color = ActionPhase)) + geom_density() # ggplot(fish_lmb2, aes(x = ActionPhase, y = Count)) + geom_col() # This works best for data with lots of zeros ### 3. One-sample t-test: Is the Count greater than 0? --------------------------------------- (lmb.ttest3 &lt;- t.test(fish_lmb2$Count, mu = 0)) # p &lt; 0.05, Yes, it is ## ## One Sample t-test ## ## data: fish_lmb2$Count ## t = 17.633, df = 1981, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 1.165012 1.456583 ## sample estimates: ## mean of x ## 1.310797 10.2 Non-parametric Statistics "],["glm-and-glmm.html", "Chapter 11 GLM and GLMM", " Chapter 11 GLM and GLMM "],["gam-and-gamm.html", "Chapter 12 GAM and GAMM", " Chapter 12 GAM and GAMM "],["multivariate-stats.html", "Chapter 13 Multivariate Stats 13.1 Load data 13.2 PCA 13.3 Cluster analysis 13.4 NMDS 13.5 PERMANOVA 13.6 CCA 13.7 Load packages", " Chapter 13 Multivariate Stats 13.1 Load data Get fish data from LTMRdata # install.packages(&quot;devtools&quot;) # devtools::install_github(&quot;sbashevkin/LTMRdata&quot;) library(LTMRdata) str(Baystudy) ## tibble [764,592 x 23] (S3: tbl_df/tbl/data.frame) ## $ Source : chr [1:764592] &quot;Bay Study&quot; &quot;Bay Study&quot; &quot;Bay Study&quot; &quot;Bay Study&quot; ... ## $ Station : chr [1:764592] &quot;101&quot; &quot;101&quot; &quot;101&quot; &quot;101&quot; ... ## $ Latitude : num [1:764592] 37.5 37.5 37.5 37.5 37.5 ... ## $ Longitude : num [1:764592] -122 -122 -122 -122 -122 ... ## $ Date : POSIXct[1:764592], format: &quot;1980-01-23&quot; &quot;1980-01-23&quot; ... ## $ Datetime : POSIXct[1:764592], format: &quot;1980-01-23 07:49:00&quot; &quot;1980-01-23 07:49:00&quot; ... ## $ Survey : int [1:764592] 1 1 1 1 1 1 1 1 1 1 ... ## $ Depth : num [1:764592] 12.2 12.2 12.2 12.2 12.2 12.2 12.2 12.2 12.2 12.2 ... ## $ SampleID : chr [1:764592] &quot;Bay Study 1&quot; &quot;Bay Study 1&quot; &quot;Bay Study 1&quot; &quot;Bay Study 1&quot; ... ## $ Method : chr [1:764592] &quot;Midwater trawl&quot; &quot;Midwater trawl&quot; &quot;Midwater trawl&quot; &quot;Midwater trawl&quot; ... ## $ Tide : chr [1:764592] NA NA NA NA ... ## $ Sal_surf : num [1:764592] 20.5 20.5 20.5 20.5 20.5 ... ## $ Temp_surf : num [1:764592] 11.5 11.5 11.5 11.5 11.5 11.5 11.5 11.5 11.5 11.5 ... ## $ Secchi : num [1:764592] 86 86 86 86 86 86 86 86 86 86 ... ## $ Tow_duration : num [1:764592] NA NA NA NA NA NA NA NA NA NA ... ## $ Tow_area : num [1:764592] NA NA NA NA NA NA NA NA NA NA ... ## $ Tow_volume : num [1:764592] 5603 5603 5603 5603 5603 ... ## $ Tow_direction : chr [1:764592] NA NA NA NA ... ## $ Taxa : chr [1:764592] &quot;Atherinops affinis&quot; &quot;Atherinopsis californiensis&quot; &quot;Clupea pallasii&quot; &quot;Clupea pallasii&quot; ... ## $ Length : num [1:764592] 95 271 78 80 81 82 85 90 37 50 ... ## $ Count : num [1:764592] 1 1 2 2 1 1 1 2 1 1 ... ## $ Length_NA_flag: chr [1:764592] NA NA NA NA ... ## $ Notes_tow : chr [1:764592] NA NA NA NA ... unique(Baystudy$Station) ## [1] &quot;101&quot; &quot;102&quot; &quot;103&quot; &quot;104&quot; &quot;105&quot; &quot;106&quot; &quot;107&quot; &quot;108&quot; &quot;109&quot; &quot;110&quot; &quot;211&quot; &quot;212&quot; ## [13] &quot;213&quot; &quot;214&quot; &quot;215&quot; &quot;216&quot; &quot;317&quot; &quot;318&quot; &quot;319&quot; &quot;320&quot; &quot;321&quot; &quot;322&quot; &quot;323&quot; &quot;324&quot; ## [25] &quot;325&quot; &quot;326&quot; &quot;427&quot; &quot;428&quot; &quot;429&quot; &quot;430&quot; &quot;431&quot; &quot;432&quot; &quot;433&quot; &quot;534&quot; &quot;535&quot; &quot;736&quot; ## [37] &quot;837&quot; &quot;140&quot; &quot;141&quot; &quot;142&quot; &quot;243&quot; &quot;244&quot; &quot;345&quot; &quot;346&quot; &quot;447&quot; &quot;750&quot; &quot;751&quot; &quot;752&quot; ## [49] &quot;853&quot; &quot;760&quot; &quot;761&quot; &quot;762&quot; &quot;863&quot; &quot;864&quot; &quot;865&quot; &quot;753&quot; baystudy_latlon &lt;- Baystudy %&gt;% select(Latitude, Longitude, Station) %&gt;% distinct() ggplot(baystudy_latlon, aes(x = Longitude, y = Latitude, label = Station)) + geom_point() + geom_text() baystudy_subset &lt;- Baystudy %&gt;% filter(Station %in% c(101, 320, 428, 805), year(Date) &gt; 2014, Method == &quot;Otter trawl&quot;, !is.na(Count)) %&gt;% mutate(CPUE = Count/Tow_area, Month = as.numeric(month(Date)), WY = wateRshedTools::wtr_yr(Date), Season = case_when(Month &gt;=1 &amp; Month&lt;=3 ~ &quot;Winter&quot;, Month&gt;3 &amp; Month&lt;=6 ~ &quot;Spring&quot;, Month &gt; 6 &amp; Month &lt;=9 ~ &quot;Summer&quot;, TRUE ~ &quot;Fall&quot;)) %&gt;% left_join(WYType %&gt;% select(WYType_Sac, WY)) %&gt;% select(-Length) %&gt;% arrange(Taxa) %&gt;% distinct() 13.2 PCA 13.3 Cluster analysis 13.4 NMDS Fill zeros baystudy_wide &lt;- pivot_wider(baystudy_subset, names_from = &quot;Taxa&quot;, values_from = CPUE, values_fill = 0) baystudy_long &lt;- pivot_longer(baystudy_wide, cols = `Acanthogobius flavimanus`:`Tridentiger trigonocephalus`, values_to = &quot;CPUE&quot;, names_to = &quot;Taxa&quot;) Remove rare species numSamples = nrow(baystudy_wide) prop &lt;- baystudy_long %&gt;% filter(CPUE&gt;0) %&gt;% group_by(Taxa) %&gt;% summarize(n = n(), percent = round(n/numSamples*100,2)) fish_abund &lt;- prop %&gt;% filter(percent&gt;5) baystudy_nmds &lt;- filter(baystudy_long, Taxa %in% fish_abund$Taxa) fish1 &lt;- first(fish_abund$Taxa) fishlast &lt;- last(fish_abund$Taxa) Make species matrix spMatrixAll &lt;- baystudy_nmds %&gt;% pivot_wider(names_from = &quot;Taxa&quot;, values_from = CPUE, values_fill = 0) %&gt;% dplyr::select(Station, Season, WYClass = WYType_Sac, Month, Date, fish1:fishlast) # Remove any row where there is no catch for the day. spMatrix &lt;- spMatrixAll %&gt;% mutate(Total = dplyr::select(., fish1:fishlast) %&gt;% rowSums(na.rm = TRUE)) %&gt;% filter(Total !=0) Run NMDS # ncolbelow &lt;- ncol(spMatrix)-1 # library(vegan) # nmds &lt;- metaMDS(spMatrix[,6:ncolbelow], distance=&quot;bray&quot;, k=3, trymax=400, autotransform = FALSE) # nmds # # stressplot(nmds) 13.5 PERMANOVA 13.6 CCA 13.7 Load packages "],["time-series.html", "Chapter 14 Time Series", " Chapter 14 Time Series "],["github.html", "Chapter 15 GitHub", " Chapter 15 GitHub "],["useful-resources.html", "Chapter 16 Useful Resources", " Chapter 16 Useful Resources "],["instructions.html", "Chapter 17 Instructions 17.1 About 17.2 Introduction 17.3 Cross references and chapters 17.4 Captioned figures and tables 17.5 Parts 17.6 Footnotes and Citations 17.7 Blocks 17.8 Publishing", " Chapter 17 Instructions 17.1 About This is a sample book written in Markdown. You can use anything that Pandocs Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). 17.1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 17.1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select All formats if youd like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, youll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 17.1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in Preview book, or from the R console: bookdown::serve_book() 17.2 Introduction All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (#) per .Rmd file. 17.2.1 A section All chapter sections start with a second-level (##) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. 17.3 Cross references and chapters ###Cross-references {#cross} Cross-references make it easier for your readers to find and link to elements in your book. 17.3.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter ??. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 17.4 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 17.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 17.1: Here is a nice figure! Dont miss Table 17.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 17.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 17.5 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. 17.6 Footnotes and Citations Footnotes and citations 17.6.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one.1 17.6.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2021) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations 17.7 Blocks 17.7.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{17.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (17.1). 17.7.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 17.1. Theorem 17.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 17.7.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html 17.8 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 17.8.1 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If youd like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 17.8.2 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your books title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your books source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapters source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook References "],["references-1.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
